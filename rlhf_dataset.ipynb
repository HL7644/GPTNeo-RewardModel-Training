{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyungmoonko/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#library for data processing\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from itertools import combinations\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "import accelerate\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer, AdamW, get_scheduler, GPTNeoModel, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#from torchrl.data import PrioritizedReplayBuffer, ReplayBuffer\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import pickle\n",
    "import gym\n",
    "\n",
    "base_dir=\".\"\n",
    "\n",
    "accelerator=accelerate.Accelerator()\n",
    "device=accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_thresh=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all datasets\n",
    "from dataset_classes.hf_dataset import HFDataset\n",
    "from dataset_classes.state_action_dataset import StateActionDataset\n",
    "from dataset_classes.ep_steps_dataset import EpStepsDataset\n",
    "from dataset_classes.eli5_and_hf_dataset import ELI5andHFDataset\n",
    "from dataset_classes.chosen_dataset import ChosenDataset\n",
    "from dataset_classes.eli5_dataset import ELI5Dataset\n",
    "from dataset_classes.instruct_dataset import InstructDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELI5 dataset\n",
    "eli5 = load_dataset(\"eli5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can be used for more extensive RM training\n",
    "#compare with Anthropic data trained RM => generalize with each othter\n",
    "train_eli5_dset=ELI5Dataset(eli5['train_eli5'], short=False)\n",
    "val_eli5_dset=ELI5Dataset(eli5['validation_eli5'], short=False)\n",
    "test_eli5_dset=ELI5Dataset(eli5['test_eli5'], short=False)\n",
    "eli5_data={\n",
    "    'train_data': train_eli5_dset,\n",
    "    'val_data': val_eli5_dset,\n",
    "    'test_data': test_eli5_dset\n",
    "}\n",
    "\n",
    "short_train_eli5_dset=ELI5Dataset(eli5['train_eli5'], short=True)\n",
    "short_val_eli5_dset=ELI5Dataset(eli5['validation_eli5'], short=True)\n",
    "short_test_eli5_dset=ELI5Dataset(eli5['test_eli5'], short=True)\n",
    "short_eli5_data={\n",
    "    'train_data': short_train_eli5_dset,\n",
    "    'val_data': short_val_eli5_dset,\n",
    "    'test_data': short_test_eli5_dset\n",
    "}\n",
    "\n",
    "#save them\n",
    "with open(os.path.join(base_dir, 'data/eli5_data.pkl'), 'wb') as file:\n",
    "  pickle.dump(eli5_data, file)\n",
    "with open(os.path.join(base_dir, 'data/short_eli5_data.pkl'), 'wb') as file:\n",
    "  pickle.dump(short_eli5_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use science and history data => concatenate and random split to create 2 dsets for sft and policy (at a ratio of 0.3/0.7)\n",
    "#make it into state, action dataset\n",
    "science_train_eli5_dset=ELI5Dataset(eli5['train_asks'], short=False)\n",
    "science_val_eli5_dset=ELI5Dataset(eli5['validation_asks'], short=False)\n",
    "science_test_eli5_dset=ELI5Dataset(eli5['test_asks'], short=False)\n",
    "\n",
    "\n",
    "history_train_eli5_dset=ELI5Dataset(eli5['train_askh'], short=False)\n",
    "history_val_eli5_dset=ELI5Dataset(eli5['validation_askh'], short=False)\n",
    "history_test_eli5_dset=ELI5Dataset(eli5['test_askh'], short=False)\n",
    "\n",
    "history_eli5_dset=torch.utils.data.ConcatDataset([history_train_eli5_dset, history_val_eli5_dset, history_test_eli5_dset])\n",
    "\n",
    "#concatenate datasets\n",
    "sh_train_eli5_dset=torch.utils.data.ConcatDataset([science_train_eli5_dset, history_train_eli5_dset])\n",
    "sh_val_eli5_dset=torch.utils.data.ConcatDataset([science_val_eli5_dset, history_val_eli5_dset])\n",
    "sh_test_eli5_dset=torch.utils.data.ConcatDataset([science_test_eli5_dset, history_test_eli5_dset])\n",
    "\n",
    "#divide datasets into sft and policy\n",
    "sh_train_eli5_dset_sft, sh_train_eli5_dset_policy=torch.utils.data.random_split(sh_train_eli5_dset, [0.3, 0.7])\n",
    "sh_val_eli5_dset_sft, sh_val_eli5_dset_policy=torch.utils.data.random_split(sh_val_eli5_dset, [0.3, 0.7])\n",
    "sh_test_eli5_dset_sft, sh_test_eli5_dset_policy=torch.utils.data.random_split(sh_test_eli5_dset, [0.3, 0.7])\n",
    "\n",
    "\n",
    "sh_eli5_data_sft={\n",
    "    'train_data': sh_train_eli5_dset_sft,\n",
    "    'val_data': sh_val_eli5_dset_sft,\n",
    "    'test_data': sh_test_eli5_dset_sft\n",
    "}\n",
    "sh_eli5_data_policy={\n",
    "    'train_data': sh_train_eli5_dset_policy,\n",
    "    'val_data': sh_val_eli5_dset_policy,\n",
    "    'test_data': sh_test_eli5_dset_policy\n",
    "}\n",
    "\n",
    "#save them\n",
    "with open(os.path.join(base_dir, 'data/components/sh_eli5_data_sft.pkl'), 'wb') as file:\n",
    "  pickle.dump(sh_eli5_data_sft, file)\n",
    "with open(os.path.join(base_dir, 'data/components/sh_eli5_data_policy.pkl'), 'wb') as file:\n",
    "  pickle.dump(sh_eli5_data_policy, file)\n",
    "\n",
    "short_science_train_eli5_dset=ELI5Dataset(eli5['train_asks'], short=True)\n",
    "short_science_val_eli5_dset=ELI5Dataset(eli5['validation_asks'], short=True)\n",
    "short_science_test_eli5_dset=ELI5Dataset(eli5['test_asks'], short=True)\n",
    "\n",
    "short_history_train_eli5_dset=ELI5Dataset(eli5['train_askh'], short=True)\n",
    "short_history_val_eli5_dset=ELI5Dataset(eli5['validation_askh'], short=True)\n",
    "short_history_test_eli5_dset=ELI5Dataset(eli5['test_askh'], short=True)\n",
    "\n",
    "#concatenate datasets\n",
    "short_sh_train_eli5_dset=torch.utils.data.ConcatDataset([short_science_train_eli5_dset, short_history_train_eli5_dset])\n",
    "short_sh_val_eli5_dset=torch.utils.data.ConcatDataset([short_science_val_eli5_dset, short_history_val_eli5_dset])\n",
    "short_sh_test_eli5_dset=torch.utils.data.ConcatDataset([short_science_test_eli5_dset, short_history_test_eli5_dset])\n",
    "\n",
    "print(len(short_sh_train_eli5_dset), len(short_sh_val_eli5_dset), len(short_sh_test_eli5_dset))\n",
    "\n",
    "#divide datasets into sft and policy\n",
    "short_sh_train_eli5_dset_sft, short_sh_train_eli5_dset_policy=torch.utils.data.random_split(short_sh_train_eli5_dset, [0.3, 0.7])\n",
    "short_sh_val_eli5_dset_sft, short_sh_val_eli5_dset_policy=torch.utils.data.random_split(short_sh_val_eli5_dset, [0.3, 0.7])\n",
    "short_sh_test_eli5_dset_sft, short_sh_test_eli5_dset_policy=torch.utils.data.random_split(short_sh_test_eli5_dset, [0.3, 0.7])\n",
    "\n",
    "short_sh_eli5_data_sft={\n",
    "    'train_data': short_sh_train_eli5_dset_sft,\n",
    "    'val_data': short_sh_val_eli5_dset_sft,\n",
    "    'test_data': short_sh_test_eli5_dset_sft\n",
    "}\n",
    "short_sh_eli5_data_policy={\n",
    "    'train_data': short_sh_train_eli5_dset_policy,\n",
    "    'val_data': short_sh_val_eli5_dset_policy,\n",
    "    'test_data': short_sh_test_eli5_dset_policy\n",
    "}\n",
    "\n",
    "#save them\n",
    "with open(os.path.join(base_dir, 'data/components/short_sh_eli5_data_sft.pkl'), 'wb') as file:\n",
    "  pickle.dump(short_sh_eli5_data_sft, file)\n",
    "with open(os.path.join(base_dir, 'data/components/short_sh_eli5_data_policy.pkl'), 'wb') as file:\n",
    "  pickle.dump(short_sh_eli5_data_policy, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anthropic Datasets\n",
    "train_dataset = load_dataset(\"Anthropic/hh-rlhf\", split=\"train\")\n",
    "test_dataset= load_dataset(\"Anthropic/hh-rlhf\", split=\"test\")\n",
    "\n",
    "helpful_base=load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-base\", split=\"train\")\n",
    "helpful_base_train, helpful_base_val=torch.utils.data.random_split(helpful_base, [0.95,0.05])\n",
    "helpful_base_test=load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-base\", split=\"test\")\n",
    "\n",
    "helpful_online=load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-online\", split=\"train\")\n",
    "helpful_online_train, helpful_online_val=torch.utils.data.random_split(helpful_online, [0.95, 0.05])\n",
    "helpful_online_test=load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-online\", split=\"test\")\n",
    "\n",
    "helpful_rej=load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-rejection-sampled\", split=\"train\")\n",
    "helpful_rej_train, helpful_rej_val=torch.utils.data.random_split(helpful_rej, [0.95, 0.05])\n",
    "helpful_rej_test=load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"helpful-rejection-sampled\", split=\"test\")\n",
    "\n",
    "#length of base, online, rej: 43835, 22007, 52421\n",
    "#for RM training: \n",
    "#for policy training: \n",
    "\n",
    "helpful_train=torch.utils.data.ConcatDataset([helpful_base_train, helpful_online_train, helpful_rej_train])\n",
    "helpful_val=torch.utils.data.ConcatDataset([helpful_base_val, helpful_online_val, helpful_rej_val])\n",
    "helpful_test=torch.utils.data.ConcatDataset([helpful_base_test, helpful_online_test, helpful_rej_test])\n",
    "\n",
    "#divide SFT 20% and rest in half for RM training and policy training\n",
    "helpful_train_sft, helpful_train_rm, helpful_train_policy=torch.utils.data.random_split(helpful_train, [0.2, 0.4, 0.4])\n",
    "helpful_val_sft, helpful_val_rm, helpful_val_policy=torch.utils.data.random_split(helpful_val, [0.2, 0.4, 0.4])\n",
    "helpful_test_sft, helpful_test_rm, helpful_test_policy=torch.utils.data.random_split(helpful_test, [0.2,0.4, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#short data to reduce tokens during training.\n",
    "short_chosen_sft_data={\n",
    "    'train_data': ChosenDataset(helpful_train_sft, short=True),\n",
    "    'val_data': ChosenDataset(helpful_val_sft, short=True),\n",
    "    'test_data': ChosenDataset(helpful_test_sft, short=True)\n",
    "}\n",
    "short_state_action_sft_data={\n",
    "    'train_data': StateActionDataset(helpful_train_sft, short=True),\n",
    "    'val_data': StateActionDataset(helpful_val_sft, short=True),\n",
    "    'test_data': StateActionDataset(helpful_test_sft, short=True)\n",
    "}\n",
    "short_rm_data={\n",
    "    'train_data': HFDataset(helpful_train_rm, short=True),\n",
    "    'val_data': HFDataset(helpful_val_rm, short=True),\n",
    "    'test_data': HFDataset(helpful_test_rm, short=True)\n",
    "}\n",
    "short_chosen_policy_data={\n",
    "    'train_data': ChosenDataset(helpful_train_policy, short=True),\n",
    "    'val_data': ChosenDataset(helpful_val_policy, short=True),\n",
    "    'test_data': ChosenDataset(helpful_test_policy, short=True)\n",
    "}\n",
    "short_state_action_policy_data={\n",
    "    'train_data': StateActionDataset(helpful_train_policy, short=True),\n",
    "    'val_data': StateActionDataset(helpful_val_policy, short=True),\n",
    "    'test_data': StateActionDataset(helpful_test_policy, short=True),\n",
    "}\n",
    "short_ep_step_policy_data={\n",
    "    'train_data': EpStepsDataset(helpful_train_policy, short=True),\n",
    "    'val_data': EpStepsDataset(helpful_val_policy, short=True),\n",
    "    'test_data': EpStepsDataset(helpful_test_policy, short=True)\n",
    "}\n",
    "short_initial_prompt_policy_data={\n",
    "    'train_data': InitialPromptDataset(helpful_train_policy, short=True),\n",
    "    'val_data': InitialPromptDataset(helpful_val_policy, short=True),\n",
    "    'test_data': InitialPromptDataset(helpful_test_policy, short=True)\n",
    "}\n",
    "\n",
    "with open(os.path.join(base_dir, \"data/components/short_chosen_sft_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(short_chosen_sft_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/short_state_action_sft_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(short_state_action_sft_data, file)\n",
    "with open(os.path.join(base_dir, \"data/short_rm_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(short_rm_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/short_chosen_policy_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(short_chosen_policy_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/short_state_action_policy_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(short_state_action_policy_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/short_ep_step_policy_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(short_ep_step_policy_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/short_initial_prompt_policy_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(short_initial_prompt_policy_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full data for sufficient compute resources\n",
    "chosen_sft_data={\n",
    "    'train_data': ChosenDataset(helpful_train_sft, short=False),\n",
    "    'val_data': ChosenDataset(helpful_val_sft, short=False),\n",
    "    'test_data': ChosenDataset(helpful_test_sft, short=False)\n",
    "}\n",
    "state_action_sft_data={\n",
    "    'train_data': StateActionDataset(helpful_train_sft, short=False),\n",
    "    'val_data': StateActionDataset(helpful_val_sft, short=False),\n",
    "    'test_data': StateActionDataset(helpful_test_sft, short=False)\n",
    "}\n",
    "rm_data={\n",
    "    'train_data': HFDataset(helpful_train_rm, short=False),\n",
    "    'val_data': HFDataset(helpful_val_rm, short=False),\n",
    "    'test_data': HFDataset(helpful_test_rm, short=False)\n",
    "}\n",
    "chosen_policy_data={\n",
    "    'train_data': ChosenDataset(helpful_train_policy, short=False),\n",
    "    'val_data': ChosenDataset(helpful_val_policy, short=False),\n",
    "    'test_data': ChosenDataset(helpful_test_policy, short=False)\n",
    "}\n",
    "state_action_policy_data={\n",
    "    'train_data': StateActionDataset(helpful_train_policy, short=False),\n",
    "    'val_data': StateActionDataset(helpful_val_policy, short=False),\n",
    "    'test_data': StateActionDataset(helpful_test_policy, short=False),\n",
    "}\n",
    "ep_step_policy_data={\n",
    "    'train_data': EpStepsDataset(helpful_train_policy, short=False),\n",
    "    'val_data': EpStepsDataset(helpful_val_policy, short=False),\n",
    "    'test_data': EpStepsDataset(helpful_test_policy, short=False)\n",
    "}\n",
    "initial_prompt_policy_data={\n",
    "    'train_data': InitialPromptDataset(helpful_train_policy, short=True),\n",
    "    'val_data': InitialPromptDataset(helpful_val_policy, short=True),\n",
    "    'test_data': InitialPromptDataset(helpful_test_policy, short=True)\n",
    "}\n",
    "\n",
    "with open(os.path.join(base_dir, \"data/components/chosen_sft_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(chosen_sft_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/state_action_sft_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(state_action_sft_data, file)\n",
    "with open(os.path.join(base_dir, \"data/rm_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(rm_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/chosen_policy_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(chosen_policy_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/state_action_policy_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(state_action_policy_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/ep_step_policy_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(ep_step_policy_data, file)\n",
    "with open(os.path.join(base_dir, \"data/components/initial_prompt_policy_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(initial_prompt_policy_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read rm data\n",
    "with open(os.path.join(base_dir, 'data/rm_data.pkl'), 'rb') as file:\n",
    "  helpful_rm=pickle.load(file)\n",
    "htrain=helpful_rm['train_data']\n",
    "hval=helpful_rm['val_data']\n",
    "htest=helpful_rm['test_data']\n",
    "helpful_train_rm=[]\n",
    "for htr_data in htrain:\n",
    "  chosen, rejected=htr_data\n",
    "  helpful_train_rm.append({'chosen': chosen, 'rejected': rejected})\n",
    "helpful_val_rm=[]\n",
    "for htr_data in hval:\n",
    "  chosen, rejected=htr_data\n",
    "  helpful_val_rm.append({'chosen': chosen, 'rejected': rejected})\n",
    "helpful_test_rm=[]\n",
    "for htr_data in htest:\n",
    "  chosen, rejected=htr_data\n",
    "  helpful_test_rm.append({'chosen': chosen, 'rejected': rejected})\n",
    "\n",
    "#Concatenate ELI5 and Anthropic HF dataset\n",
    "eli5_and_hf_train=ELI5andHFDataset(eli5['train_eli5'], helpful_train_rm, short=False)\n",
    "eli5_and_hf_val=ELI5andHFDataset(eli5['validation_eli5'], helpful_val_rm, short=False)\n",
    "eli5_and_hf_test=ELI5andHFDataset(eli5['test_eli5'], helpful_test_rm, short=False)\n",
    "\n",
    "eli5_and_hf_data={\n",
    "    'train_data': eli5_and_hf_train,\n",
    "    'val_data': eli5_and_hf_val,\n",
    "    'test_data': eli5_and_hf_test\n",
    "}\n",
    "\n",
    "short_eli5_and_hf_train=ELI5andHFDataset(eli5['train_eli5'], helpful_train_rm, short=True)\n",
    "short_eli5_and_hf_val=ELI5andHFDataset(eli5['validation_eli5'], helpful_val_rm, short=True)\n",
    "short_eli5_and_hf_test=ELI5andHFDataset(eli5['test_eli5'], helpful_test_rm, short=True)\n",
    "\n",
    "short_eli5_and_hf_data={\n",
    "    'train_data': short_eli5_and_hf_train,\n",
    "    'val_data': short_eli5_and_hf_val,\n",
    "    'test_data': short_eli5_and_hf_test\n",
    "}\n",
    "with open(os.path.join(base_dir, \"data/eli5_and_hf_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(eli5_and_hf_data, file)\n",
    "with open(os.path.join(base_dir, \"data/short_eli5_and_hf_data.pkl\"), 'wb') as file:\n",
    "  pickle.dump(short_eli5_and_hf_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mix the eli5 sh dataset with sft, policy HF dataset\n",
    "\n",
    "#original version\n",
    "#open the sft, policy hf datasets\n",
    "with open(os.path.join(base_dir, 'data/components/state_action_sft_data.pkl'), 'rb') as file:\n",
    "  state_action_sft_data=pickle.load(file)\n",
    "with open(os.path.join(base_dir, 'data/components/state_action_policy_data.pkl'), 'rb') as file:\n",
    "  state_action_policy_data=pickle.load(file)\n",
    "with open(os.path.join(base_dir, 'data/components/ep_step_policy_data.pkl'), 'rb') as file:\n",
    "  ep_steps_policy_data=pickle.load(file)\n",
    "\n",
    "#for SFT\n",
    "sft_train_data=InstructDataset(state_action_sft_data['train_data'], sh_train_eli5_dset_sft, short=False)\n",
    "sft_val_data=InstructDataset(state_action_sft_data['val_data'], sh_val_eli5_dset_sft, short=False)\n",
    "sft_test_data=InstructDataset(state_action_sft_data['test_data'], sh_test_eli5_dset_sft, short=False)\n",
    "sft_data={\n",
    "    'train_data': sft_train_data,\n",
    "    'val_data': sft_val_data,\n",
    "    'test_data': sft_test_data\n",
    "}\n",
    "\n",
    "#for Policy\n",
    "#chosen, state, action dset(instruct) => also used for on-policy training\n",
    "instruct_train_data=InstructDataset(state_action_policy_data['train_data'], sh_train_eli5_dset_policy, short=False)\n",
    "instruct_val_data=InstructDataset(state_action_policy_data['val_data'], sh_val_eli5_dset_policy, short=False)\n",
    "instruct_test_data=InstructDataset(state_action_policy_data['test_data'], sh_test_eli5_dset_policy, short=False)\n",
    "instruct_data={\n",
    "    'train_data': instruct_train_data,\n",
    "    'val_data': instruct_val_data,\n",
    "    'test_data': instruct_test_data\n",
    "}\n",
    "\n",
    "#episode step dataset\n",
    "off_policy_train_data=OffPolicyDataset(ep_steps_policy_data['train_data'], sh_train_eli5_dset_policy, short=False)\n",
    "off_policy_val_data=OffPolicyDataset(ep_steps_policy_data['val_data'], sh_val_eli5_dset_policy, short=False)\n",
    "off_policy_test_data=OffPolicyDataset(ep_steps_policy_data['test_data'], sh_test_eli5_dset_policy, short=False)\n",
    "off_policy_data={\n",
    "    'train_data': off_policy_train_data,\n",
    "    'val_data': off_policy_val_data,\n",
    "    'test_data': off_policy_test_data\n",
    "}\n",
    "\n",
    "#save them\n",
    "with open(os.path.join(base_dir, 'data/sft_data.pkl'), 'wb') as file:\n",
    "  pickle.dump(sft_data, file)\n",
    "with open(os.path.join(base_dir, 'data/instruct_data.pkl'), 'wb') as file:\n",
    "  pickle.dump(instruct_data, file)\n",
    "with open(os.path.join(base_dir, 'data/off_policy_data.pkl'), 'wb') as file:\n",
    "  pickle.dump(off_policy_data, file)\n",
    "\n",
    "#short version\n",
    "#open the sft, policy hf datasets\n",
    "with open(os.path.join(base_dir, 'data/components/short_state_action_sft_data.pkl'), 'rb') as file:\n",
    "  short_state_action_sft_data=pickle.load(file)\n",
    "with open(os.path.join(base_dir, 'data/components/short_state_action_policy_data.pkl'), 'rb') as file:\n",
    "  short_state_action_policy_data=pickle.load(file)\n",
    "with open(os.path.join(base_dir, 'data/components/short_ep_step_policy_data.pkl'), 'rb') as file:\n",
    "  short_ep_steps_policy_data=pickle.load(file)\n",
    "\n",
    "#for SFT\n",
    "short_sft_train_data=InstructDataset(short_state_action_sft_data['train_data'], short_sh_train_eli5_dset_sft, short=True)\n",
    "short_sft_val_data=InstructDataset(short_state_action_sft_data['val_data'], short_sh_val_eli5_dset_sft, short=True)\n",
    "short_sft_test_data=InstructDataset(short_state_action_sft_data['test_data'], short_sh_test_eli5_dset_sft, short=True)\n",
    "short_sft_data={\n",
    "    'train_data': short_sft_train_data,\n",
    "    'val_data': short_sft_val_data,\n",
    "    'test_data': short_sft_test_data\n",
    "}\n",
    "\n",
    "#for Policy\n",
    "#chosen, state, action dset(instruct)\n",
    "short_instruct_train_data=InstructDataset(short_state_action_policy_data['train_data'], short_sh_train_eli5_dset_policy, short=True)\n",
    "short_instruct_val_data=InstructDataset(short_state_action_policy_data['val_data'], short_sh_val_eli5_dset_policy, short=True)\n",
    "short_instruct_test_data=InstructDataset(short_state_action_policy_data['test_data'], short_sh_test_eli5_dset_policy, short=True)\n",
    "short_instruct_data={\n",
    "    'train_data': short_instruct_train_data,\n",
    "    'val_data': short_instruct_val_data,\n",
    "    'test_data': short_instruct_test_data\n",
    "}\n",
    "\n",
    "#episode step dataset\n",
    "short_off_policy_train_data=OffPolicyDataset(short_ep_steps_policy_data['train_data'], short_sh_train_eli5_dset_policy, short=True)\n",
    "short_off_policy_val_data=OffPolicyDataset(short_ep_steps_policy_data['val_data'], short_sh_val_eli5_dset_policy, short=True)\n",
    "short_off_policy_test_data=OffPolicyDataset(short_ep_steps_policy_data['test_data'], short_sh_test_eli5_dset_policy, short=True)\n",
    "short_off_policy_data={\n",
    "    'train_data': short_off_policy_train_data,\n",
    "    'val_data': short_off_policy_val_data,\n",
    "    'test_data': short_off_policy_test_data\n",
    "}\n",
    "\n",
    "with open(os.path.join(base_dir, 'data/short_sft_data.pkl'), 'wb') as file:\n",
    "  pickle.dump(short_sft_data, file)\n",
    "with open(os.path.join(base_dir, 'data/short_instruct_data.pkl'), 'wb') as file:\n",
    "  pickle.dump(short_instruct_data, file)\n",
    "with open(os.path.join(base_dir, 'data/short_off_policy_data.pkl'), 'wb') as file:\n",
    "  pickle.dump(short_off_policy_data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "641a7458bfae2bc959d7f867e9e3882167acabe29543290f7c5231fa0d54378e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
